{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 03 Developing the SOM algorithm\n",
    "\n",
    "In this notebook the functions used to train the SOM are tested to tune\n",
    "the hyperparameters:\n",
    "\n",
    "- Choice of alpha function (exponential decay or percentage of datapoints remaining)\n",
    "- Choice of theta function (nearest neighbours only or Gaussian function)\n",
    "- Alpha parameters - rate of decay, initial value\n",
    "- Size of matrix\n",
    "- Size of training data (equivalent to number of training iterations)\n",
    "\n",
    "The size of the matrix will initially be approximated as:  \n",
    "\n",
    "$$M = 5 \\sqrt{N} \\quad (1)$$ \n",
    " <div style=\"text-align: right\"><i>(Tian et al., 2014)</i></div>\n",
    "\n",
    "where:\n",
    " - M = Number of nodes\n",
    " - N = number of observations used to train the matrix.\n",
    " \n",
    " All functions used to train the matrix are stored in `featureextractionsom/som_adjustable_parameters.py`\n",
    "\n",
    "## 3.1 Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pickle import load\n",
    "from featureextractionsom.config import data_path\n",
    "data_path = 'data'\n",
    "training_data = load(open(data_path + '/training_data.pkl', 'rb'))\n",
    "test_vectors = load(open(data_path + '/test_vectors.pkl', 'rb'))\n",
    "\n",
    "num_features = training_data.shape[1] \n",
    "num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Hyper parameter tuning\n",
    "\n",
    "Initiate a dictionary of parameters that will be incrementally tuned and tested.\n",
    "\n",
    "Store the formula from Tian et al. as a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'gaussian': False, 'alpha_type': 'exp', 'half_life': 0.5, 'initial_value': 1, 'max_iterations': 100}\n",
    "\n",
    "def get_size(i: int) -> int:\n",
    "    \"\"\"\n",
    "    Apply equation 1 to return the suggested matrix size for supplied number of iterations.\n",
    "    \"\"\"\n",
    "    # number of nodes as in formula\n",
    "    num_nodes = 5 * i**0.5\n",
    "    # square root number of nodes to find number of rows/columns in square array\n",
    "    return int(num_nodes**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2.1 Initial testing\n",
    "\n",
    "The alpha function determines the learning rate of the matrix. It should decrease\n",
    "with each iteration and be initialised at a high enough value that the matrix\n",
    "adjusts to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from featureextractionsom.functions.utils import try_make_folder\n",
    "\n",
    "# set output path\n",
    "outputs = 'output'\n",
    "alpha_per_path = outputs + '/3_2_1/alpha_per'\n",
    "alpha_exp_path = outputs + '/3_2_1/alpha_exp'\n",
    "\n",
    "try_make_folder(alpha_exp_path)\n",
    "try_make_folder(alpha_per_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For each possible alpha function, test a wide range of possible initial values\n",
    "and values that determine how the alpha value decreases with each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors tested: [7, 22, 16]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from featureextractionsom.functions.som_adjustable_parameters import train_matrix\n",
    "from featureextractionsom.functions.matrix_operations import distance, build_node_matrix\n",
    "from featureextractionsom.functions.evaluation import record_response, get_test_vectors\n",
    "\n",
    "# Randomly choose 3 vectors from the validation set\n",
    "validation_set = [(i, vec) for (i, vec) in get_test_vectors(test_vectors, 3)]\n",
    "print(f'Vectors tested: {[i for i,_ in validation_set]}')\n",
    "\n",
    "# Alpha as an exponential decay function\n",
    "\n",
    "# Start with two values of max_iteration (will tune later)\n",
    "for max_iterations in [100,1000]:\n",
    "    size = get_size(max_iterations)\n",
    "    params['max_iterations'] = max_iterations\n",
    "    # build matrix\n",
    "    node_matrix = build_node_matrix(size,num_features)\n",
    "    \n",
    "    # Try twoinitial values\n",
    "    for initial_value in [0.5, 1]:\n",
    "        params['initial_val'] = initial_value\n",
    "        \n",
    "        # Try two values of *h*\n",
    "        for decay_hlife in [0.2, 0.4]:\n",
    "            params['half_life'] = decay_hlife\n",
    "            \n",
    "            # train the matrix with the hyper parameters\n",
    "            trained_matrix = train_matrix(params, node_matrix, training_data)\n",
    "            \n",
    "            # Generate matrix of distances between weights and test vectors\n",
    "            for i, test_vector in validation_set:\n",
    "                # Evaluate the matrix by finding the distance between a test vector and all of the nodes\n",
    "                distance_matrix = np.array([[distance(test_vector, node) for node in row] for row in trained_matrix])\n",
    "            \n",
    "                response_image_path = alpha_exp_path\n",
    "                response_image_path += f'/vec{i}_max_iter_{max_iterations}_initval_{initial_value}_decay_{decay_hlife}.png'\n",
    "                record_response(distance_matrix, response_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "On inspection, only limited evidence of clustering was found, see examples:\n",
    "\n",
    "Configuration | Vector 6 | Vector 13 | Vector 21\n",
    "---|---|---|---\n",
    "100 iterations, initial value 0.5, decay 0.2 |![response](output/3_2_1/alpha_exp/vec7_max_iter_100_initval_0.5_decay_0.2.png)|  ![response](output/3_2_1/alpha_exp/vec16_max_iter_100_initval_0.5_decay_0.2.png) | ![response](output/3_2_1/alpha_exp/vec22_max_iter_100_initval_0.5_decay_0.2.png)\n",
    "1000 iterations, initial value 1, decay 0.2 | ![response](output/3_2_1/alpha_exp/vec7_max_iter_1000_initval_1_decay_0.2.png)| ![response](output/3_2_1/alpha_exp/vec16_max_iter_1000_initval_1_decay_0.2.png) | ![response](output/3_2_1/alpha_exp/vec22_max_iter_1000_initval_1_decay_0.2.png)\n",
    "\n",
    "\n",
    "A different alpha function was tried.\n",
    "This alpha function decreases the learning rate proportionately to the number of vectors left to\n",
    "use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Alpha as fractional decay\n",
    "params['alpha_type'] = 'per'\n",
    "\n",
    "# Use same two values of max_iterations\n",
    "for max_iterations in [100,5000]:\n",
    "    size = get_size(max_iterations)\n",
    "    params['max_iterations'] = max_iterations\n",
    "    \n",
    "    # reset matrix\n",
    "    node_matrix = build_node_matrix(size,num_features)\n",
    "    \n",
    "    # Try the same initial values again\n",
    "    for initial_value in [0.5, 1]:\n",
    "        params['initial_val'] = initial_value\n",
    "            \n",
    "        # train the matrix with the hyper parameters\n",
    "        trained_matrix = train_matrix(params, node_matrix, training_data)\n",
    "        # Randomly choose 3 vectors from the validation set\n",
    "        for i, test_vector in validation_set:\n",
    "            # Evaluate the matrix by finding the distance between a test vector and all of the nodes\n",
    "            distance_matrix = np.array([[distance(test_vector, node) for node in row] for row in trained_matrix])\n",
    "            \n",
    "            response_image_path = alpha_per_path\n",
    "            response_image_path += f'/vec{i}_max_iter_{max_iterations}_initval_{initial_value}.png'\n",
    "            record_response(distance_matrix, response_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Again, only limited evidence of clustering was found. \n",
    "\n",
    "Vector 7:  \n",
    "\n",
    "Initial value | 100 iterations | 5000 iterations\n",
    "---|---|---\n",
    "0.5 |![response](output/3_2_1/alpha_per/vec7_max_iter_100_initval_0.5.png)|![response](output/3_2_1/alpha_per/vec7_max_iter_5000_initval_0.5.png)\n",
    "1 | ![response](output/3_2_1/alpha_per/vec7_max_iter_100_initval_1.png)|![response](output/3_2_1/alpha_per/vec7_max_iter_5000_initval_1.png)\n",
    "\n",
    "\n",
    "The exercise was repeated using a Gaussian Theta function. An additional value of max_iterations was added that falls in between the two considered above.\n",
    "\n",
    "### 3.2.2 Choosing alpha function using gaussian Theta function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alpha_per_path = outputs + '/3_2_2/alpha_per'\n",
    "alpha_exp_path = outputs + '/3_2_2/alpha_exp'\n",
    "\n",
    "try_make_folder(alpha_per_path)\n",
    "try_make_folder(alpha_exp_path)\n",
    "\n",
    "#  Choose a new validation set - this will be done periodically to avoid overfitting\n",
    "validation_set = [(i, vec) for (i, vec) in zip([7, 22, 16], [test_vectors[i] for i in [7, 22, 16]])]\n",
    "\n",
    "# Set the theta function to 'gaussian'\n",
    "params['gaussian'] = True\n",
    "\n",
    "# Alpha as an exponential decay function\n",
    "params['alpha_type'] = 'exp'\n",
    "\n",
    "# Three values of max_iterations\n",
    "for max_iterations in [100,1000,5000]:\n",
    "    size = get_size(max_iterations)\n",
    "    params['max_iterations'] = max_iterations\n",
    "    \n",
    "    # Reset the matrix\n",
    "    node_matrix = build_node_matrix(size, num_features)\n",
    "    \n",
    "    # try the same initial values\n",
    "    for initial_value in [0.5, 1]:\n",
    "        params['initial_val'] = initial_value\n",
    "        \n",
    "        for decay_hlife in [0.2, 0.4]:\n",
    "            params['half_life'] = decay_hlife\n",
    "            \n",
    "            # train the matrix with the hyper parameters\n",
    "            trained_matrix = train_matrix(params, node_matrix, training_data)\n",
    "            \n",
    "            # Generate matrix of distances between weights and test vectors\n",
    "            \n",
    "            for i, test_vector in validation_set:\n",
    "                # Evaluate the matrix by finding the distance between a test vector and all of the nodes\n",
    "                distance_matrix = np.array([[distance(test_vector, node) for node in row] for row in trained_matrix])\n",
    "                \n",
    "                # save the response\n",
    "                response_image_path = alpha_exp_path\n",
    "                response_image_path += f'/vec{i}_max_iter_{max_iterations}_initval_{initial_value}_decay_{decay_hlife}.png'\n",
    "                record_response(distance_matrix, response_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Alpha as an percentage decay\n",
    "\n",
    "params['alpha_type'] = 'per'\n",
    "\n",
    "# Three values of max_iterations\n",
    "for max_iterations in [100,1000,5000]:\n",
    "    size = get_size(max_iterations)\n",
    "    params['max_iterations'] = max_iterations\n",
    "    \n",
    "    # resest matrix\n",
    "    node_matrix = build_node_matrix(size,num_features)\n",
    "    \n",
    "    # Same initial values\n",
    "    for initial_value in [0.5, 1]:\n",
    "        params['initial_val'] = initial_value\n",
    "            \n",
    "        # train the matrix with the hyper parameters\n",
    "        trained_matrix = train_matrix(params, node_matrix, training_data)\n",
    "            \n",
    "        # Iterate through validation set\n",
    "        for i, test_vector in validation_set:\n",
    "            # Evaluate the matrix by finding the distance between a test vector and all of the nodes\n",
    "            distance_matrix = np.array([[distance(test_vector, node) for node in row] for row in trained_matrix])\n",
    "            \n",
    "            # save the response\n",
    "            response_image_path = alpha_per_path\n",
    "            response_image_path += f'/vec{i}_max_iter_{max_iterations}_initval_{initial_value}.png'\n",
    "            record_response(distance_matrix, response_image_path)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we start to see some evidence of clustering, and of clearly dilineated areas of the SOM, particularly for the exponential alpha function.\n",
    "\n",
    "Here are the responses to vector 22 with and without a Gaussian theta value:\n",
    "\n",
    "Configuration | Non-Gaussian theta function | Gaussian theta function\n",
    "---|---|---\n",
    "Alpha 'exp', 100 iterations, initial value 0.5, decay 0.4 | ![example_matrix](output/3_2_1/alpha_exp/vec22_max_iter_100_initval_0.5_decay_0.4.png)  | ![example_matrix](output/3_2_2/alpha_exp/vec22_max_iter_100_initval_0.5_decay_0.4.png)  \n",
    "Alpha 'per', 100 iterations, initial value 1 | ![example_matrix](output/3_2_1/alpha_per/vec22_max_iter_100_initval_1.png)  | ![example_matrix](output/3_2_2/alpha_per/vec22_max_iter_100_initval_1.png)  \n",
    "\n",
    "\n",
    "From now on, the Theta function used will be Gaussian.\n",
    "\n",
    "### 2.2.3 Choosing how to visualise responses\n",
    "\n",
    "In tuning the hyper-parameters by inspection, it is important to be confident in the\n",
    "method used to evaluate the response of the matrix to different input vectors.\n",
    "\n",
    "Two different sets of hyper-parameters will be used to train the node matrix.\n",
    "Each resulting matrix will be tested with two types of response: distance and dot product.\n",
    "\n",
    "The responses will be measured between the trained matrix and five different test vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "distance_matrix_path = outputs + '/3_2_3/distance_matrix'\n",
    "dot_product_matrix_path = outputs + '/3_2_3/dot_product_matrix'\n",
    "try_make_folder(distance_matrix_path)\n",
    "try_make_folder(dot_product_matrix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set up two different possible sets of hyper-parameters\n",
    "\n",
    "# Pick shared parameters for both tests\n",
    "shared_params = {'gaussian': True, 'max_iterations': 100, 'initial_val': 1}\n",
    "size = get_size(500)\n",
    "\n",
    "# Create two different configurations to test\n",
    "unique_params_one = {'alpha_type': 'exp', 'half_life': 0.4}\n",
    "unique_params_two = {'alpha_type': 'per'}\n",
    "\n",
    "# Hold both sets of parameters in a list\n",
    "paramsGrid = [{**shared_params, **unique_params_one}, {**shared_params, **unique_params_two}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors tested: [5, 21, 12, 16, 13]\n"
     ]
    }
   ],
   "source": [
    "from featureextractionsom.functions.evaluation import generate_dot_matrix\n",
    "\n",
    "# Randomly choose 5 vectors from the validation set\n",
    "validation_set = [(i, vec) for (i, vec) in get_test_vectors(test_vectors, 5)]\n",
    "print(f'Vectors tested: {[i for i,_ in validation_set]}')\n",
    "\n",
    "# for each set of parameters, create and train a matrix of nodes\n",
    "for p in range(len(paramsGrid)):\n",
    "    params = paramsGrid[p]\n",
    "    \n",
    "    # reset and train node matrix\n",
    "    node_matrix = build_node_matrix(size, num_features)\n",
    "    trained_matrix = train_matrix(params, node_matrix, training_data)\n",
    "    \n",
    "    # Iterate through validation set\n",
    "    for i, test_vector in validation_set:\n",
    "        # Evaluate the matrix by finding the distance between the test vector and all of the nodes\n",
    "        distance_matrix = np.array([[distance(test_vector, node) for node in row] for row in trained_matrix])\n",
    "        \n",
    "        # set image name\n",
    "        image_name = f'/vec{i}_matrix_{p}.png'\n",
    "        \n",
    "        # set file path\n",
    "        distance_image_path = distance_matrix_path + image_name\n",
    "        \n",
    "        # Evaluate the matrix by finding the dot product between the test vector and each weight vector in the matrix\n",
    "        dot_matrix = generate_dot_matrix(test_vectors[i], trained_matrix, size)\n",
    "        \n",
    "        # set file path\n",
    "        dot_image_path = dot_product_matrix_path + image_name\n",
    "        \n",
    "        # record response\n",
    "        record_response(distance_matrix, distance_image_path)\n",
    "        record_response(dot_matrix, dot_image_path, reverse_colourscale=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Inspecting the images, the distance matrix appears to display the output more distinctly.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Matrix | Response measure | Vector 5 | Vector 12 | Vector 21\n",
    "---|---|---|---|---\n",
    "Matrix 0 | dot product | ![example](output/3_2_3/dot_product_matrix/vec5_matrix_0.png) | ![example](output/3_2_3/dot_product_matrix/vec12_matrix_0.png) | ![example](output/3_2_3/dot_product_matrix/vec21_matrix_0.png) \n",
    "Matrix 0 | distance | ![example](output/3_2_3/distance_matrix/vec5_matrix_0.png) | ![example](output/3_2_3/distance_matrix/vec12_matrix_0.png) | ![example](output/3_2_3/distance_matrix/vec21_matrix_0.png) \n",
    "Matrix 1 | dot product | ![example](output/3_2_3/dot_product_matrix/vec5_matrix_1.png) | ![example](output/3_2_3/dot_product_matrix/vec12_matrix_1.png) | ![example](output/3_2_3/dot_product_matrix/vec21_matrix_1.png) \n",
    "Matrix 1 | distance | ![example](output/3_2_3/distance_matrix/vec5_matrix_1.png) | ![example](output/3_2_3/distance_matrix/vec12_matrix_1.png) | ![example](output/3_2_3/distance_matrix/vec21_matrix_1.png) \n",
    "\n",
    "Because the colour scale is reversed for the figure depicting the distance matrix, yellow indicates the strongest\n",
    "response for both methods. A dot product of zero indicates orthogonal vectors with no overlap, whereas a distance of zero indicates identical vectors.\n",
    "\n",
    "Using a dot product matrix, the same node displayed a maximal response for all three vectors. The distance matrices displays a greater variation in responses and more evidence of clustering. Going forward, the distance between the test vectors and the weight vectors will be used to evaluate the \n",
    "training parameters.\n",
    "\n",
    "### 3.2.4 Choosing the number of iterations\n",
    "\n",
    "Inspecting all previously generated outputs, it appears that the number of iterations\n",
    "used to train the matrix should be between 100 and 1000.\n",
    "\n",
    "Too many iterations leads to overfitting; too few leads to underfitting.\n",
    "\n",
    "Both potential alpha functions depend on the number of iterations, so a ballpark number\n",
    "should be chosen and used to compare the alpha functions.\n",
    "\n",
    "For now, an exponential alpha function with initial value 1 and decay halflife of 0.2 * number of iterations will be chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors tested: [4, 14, 24]\n"
     ]
    }
   ],
   "source": [
    "# Set up directories\n",
    "test_iterations_path = outputs + '/3_2_4'\n",
    "\n",
    "try_make_folder(test_iterations_path)\n",
    "\n",
    "# Set up parameters\n",
    "params = {'gaussian': True, 'alpha_type': 'exp', 'initial_val': 1, 'half_life': 0.2}\n",
    "possible_max_iterations = list(range(100,2001,100))\n",
    "\n",
    "# Randomly choose 3 vectors from the validation set\n",
    "validation_set = [(i, vec) for (i, vec) in get_test_vectors(test_vectors, 3)]\n",
    "print(f'Vectors tested: {[i for i,_ in validation_set]}')\n",
    "\n",
    "for iterations in possible_max_iterations:\n",
    "    params['max_iterations'] = iterations\n",
    "    size = get_size(iterations)\n",
    "    \n",
    "    # reset weights matrix\n",
    "    node_matrix = build_node_matrix(size, num_features)\n",
    "    \n",
    "    trained_matrix = train_matrix(params, node_matrix, training_data)\n",
    "        \n",
    "    # Randomly choose 3 vectors from the validation set\n",
    "    for i, test_vector in validation_set:      \n",
    "        # Evaluate the matrix by finding the distance between the test vector and all of the nodes\n",
    "        distance_matrix = np.array([[distance(test_vector, node) for node in row] for row in trained_matrix])\n",
    "        \n",
    "        # set file path\n",
    "        distance_image_path = test_iterations_path + f'/vec{i}_iter_{iterations}.png'\n",
    "        \n",
    "        # record response\n",
    "        record_response(distance_matrix, distance_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Inspecting the responses side by side, it appears that a greater number of iterations\n",
    "produces smaller and clearer areas of maximal response as opposed to almost all of the matrix responding.\n",
    "Above 1000 iterations, the different clusters in the matrix are clear (green) with the matching cluster to the input vector showing clearly (yellow) and the gaps and least matching clusters being blue.\n",
    "\n",
    "Number of iterations | Test vector 4 | Test vector 14 | Test vector 24 \n",
    "---|---|---|---\n",
    "100 | ![response](output/3_2_4/vec4_iter_100.png) | ![response](output/3_2_4/vec14_iter_100.png) | ![response](output/3_2_4/vec24_iter_100.png)\n",
    "400 | ![response](output/3_2_4/vec4_iter_400.png) | ![response](output/3_2_4/vec14_iter_400.png) | ![response](output/3_2_4/vec24_iter_400.png)\n",
    "600 | ![response](output/3_2_4/vec4_iter_600.png) | ![response](output/3_2_4/vec14_iter_600.png) | ![response](output/3_2_4/vec24_iter_600.png)\n",
    "800 | ![response](output/3_2_4/vec4_iter_800.png) | ![response](output/3_2_4/vec14_iter_800.png) | ![response](output/3_2_4/vec24_iter_800.png)\n",
    "1000 | ![response](output/3_2_4/vec4_iter_1000.png) | ![response](output/3_2_4/vec14_iter_1000.png) | ![response](output/3_2_4/vec24_iter_1000.png)\n",
    "1200 | ![response](output/3_2_4/vec4_iter_1200.png) | ![response](output/3_2_4/vec14_iter_1200.png) | ![response](output/3_2_4/vec24_iter_1200.png)\n",
    "1400 | ![response](output/3_2_4/vec4_iter_1400.png) | ![response](output/3_2_4/vec14_iter_1400.png) | ![response](output/3_2_4/vec24_iter_1400.png)\n",
    "1600 | ![response](output/3_2_4/vec4_iter_1600.png) | ![response](output/3_2_4/vec14_iter_1600.png) | ![response](output/3_2_4/vec24_iter_1600.png)\n",
    "1800 | ![response](output/3_2_4/vec4_iter_1800.png) | ![response](output/3_2_4/vec14_iter_1800.png) | ![response](output/3_2_4/vec24_iter_1800.png)\n",
    "2000 | ![response](output/3_2_4/vec4_iter_2000.png) | ![response](output/3_2_4/vec14_iter_2000.png) | ![response](output/3_2_4/vec24_iter_2000.png)\n",
    "\n",
    "### 3.2.5 Selecting size of weight matrix\n",
    "\n",
    "The size of the matrix has so far varied with the number of iterations according to equation $(1)$.\n",
    "To assist with narrowing down the best possible number of iterations, a range of matrix sizes will be tested for given number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors tested: [20, 8, 9, 19, 16]\n"
     ]
    }
   ],
   "source": [
    "# Set up directories\n",
    "test_sizes_path = outputs + '/3_2_5'\n",
    "try_make_folder(test_sizes_path)\n",
    "\n",
    "# set up parameters and options\n",
    "params = {'gaussian': True, 'alpha_type': 'exp', 'half_life':0.2, 'initial_val': 2}\n",
    "possible_sizes = [10,12,15]\n",
    "possible_max_iterations = list(range(100,1001,100))\n",
    "\n",
    "# Randomly choose 5 vectors from the validation set\n",
    "validation_set = [(i, vec) for (i, vec) in get_test_vectors(test_vectors, 5)]\n",
    "print(f'Vectors tested: {[i for i,_ in validation_set]}')\n",
    "\n",
    "\n",
    "for size in possible_sizes:\n",
    "    # reset node_matrix\n",
    "    node_matrix = build_node_matrix(size, num_features)\n",
    "    \n",
    "    for iterations in possible_max_iterations:\n",
    "        params['max_iterations'] = iterations\n",
    "        \n",
    "        trained_matrix = train_matrix(params, node_matrix, training_data)\n",
    "        \n",
    "        # Iterate through validation set\n",
    "        for i, test_vector in validation_set:      \n",
    "            # Evaluate the matrix by finding the distance between the test vector and all of the nodes\n",
    "            distance_matrix = np.array([[distance(test_vector, node) for node in row] for row in trained_matrix])\n",
    "        \n",
    "            # set file path\n",
    "            distance_image_path = test_sizes_path + f'/vec{i}_iter_{iterations}_size_{size}.png'\n",
    "        \n",
    "            # record response\n",
    "            record_response(distance_matrix, distance_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters | Vector 8 response | Vector 9 response | Vector 19 response\n",
    "---|---|---|---\n",
    "size 10, 400 iterations | ![example](output/3_2_5/vec8_iter_400_size_10.png) | ![example](output/3_2_5/vec9_iter_400_size_10.png) | ![example](output/3_2_5/vec19_iter_400_size_10.png) \n",
    "size 10, 1000 iterations | ![example](output/3_2_5/vec8_iter_1000_size_10.png) | ![example](output/3_2_5/vec9_iter_1000_size_10.png) | ![example](output/3_2_5/vec19_iter_1000_size_10.png) \n",
    "size 10, 1400 iterations | ![example](output/3_2_5/vec8_iter_1400_size_10.png) | ![example](output/3_2_5/vec9_iter_1400_size_10.png) | ![example](output/3_2_5/vec19_iter_1400_size_10.png) \n",
    "size 12, 400 iterations | ![example](output/3_2_5/vec8_iter_400_size_12.png) | ![example](output/3_2_5/vec9_iter_400_size_12.png) | ![example](output/3_2_5/vec19_iter_400_size_12.png) \n",
    "size 12, 1000 iterations | ![example](output/3_2_5/vec8_iter_1000_size_12.png) | ![example](output/3_2_5/vec9_iter_1000_size_12.png) | ![example](output/3_2_5/vec19_iter_1000_size_12.png) \n",
    "size 12, 1400 iterations | ![example](output/3_2_5/vec8_iter_1400_size_12.png) | ![example](output/3_2_5/vec9_iter_1400_size_12.png) | ![example](output/3_2_5/vec19_iter_1400_size_12.png) \n",
    "size 15, 400 iterations | ![example](output/3_2_5/vec8_iter_400_size_15.png) | ![example](output/3_2_5/vec9_iter_400_size_15.png) | ![example](output/3_2_5/vec19_iter_400_size_15.png) \n",
    "size 15, 1000 iterations | ![example](output/3_2_5/vec8_iter_1000_size_15.png) | ![example](output/3_2_5/vec9_iter_1000_size_15.png) | ![example](output/3_2_5/vec19_iter_1000_size_15.png) \n",
    "size 15, 1400 iterations | ![example](output/3_2_5/vec8_iter_1400_size_10.png) | ![example](output/3_2_5/vec9_iter_1400_size_15.png) | ![example](output/3_2_5/vec19_iter_1400_size_15.png) \n",
    "size 20, 400 iterations | ![example](output/3_2_5/vec8_iter_400_size_20.png) | ![example](output/3_2_5/vec9_iter_400_size_20.png) | ![example](output/3_2_5/vec19_iter_400_size_20.png) \n",
    "size 20, 1000 iterations | ![example](output/3_2_5/vec8_iter_1000_size_20.png) | ![example](output/3_2_5/vec9_iter_1000_size_20.png) | ![example](output/3_2_5/vec19_iter_1000_size_20.png) \n",
    "size 20, 1400 iterations | ![example](output/3_2_5/vec8_iter_1400_size_20.png) | ![example](output/3_2_5/vec9_iter_1400_size_20.png) | ![example](output/3_2_5/vec19_iter_1400_size_20.png) \n",
    "\n",
    "The clearest distinction between clusters in the above example is size 15. A smaller matrix seems to respond almost equally across the matrix to test vectors, larger matrices display large empty gaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.6 Selecting the type of alpha function\n",
    "\n",
    "Having settled on a size of 15, using a distance matrix to evaluate results, and a Gaussian theta function, we are now in a position to choose an appropriate combination of alpha function, alpha parameter(s), and number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors tested: [11]\n"
     ]
    }
   ],
   "source": [
    "# Set up directories\n",
    "test_alphas_path = outputs + '/3_2_6'\n",
    "alpha_exp_path = test_alphas_path + '/exp'\n",
    "alpha_per_path = test_alphas_path + '/per'\n",
    "try_make_folder(alpha_exp_path)\n",
    "try_make_folder(alpha_per_path)\n",
    "\n",
    "# Randomly choose 3 vectors from the validation set\n",
    "validation_set = [(i, vec) for (i, vec) in get_test_vectors(test_vectors, 5, 11)]\n",
    "print(f'Vectors tested: {[i for i,_ in validation_set]}')\n",
    "\n",
    "# Set up parameters and options\n",
    "params['gaussian']=True\n",
    "possible_max_iterations = [400, 800, 1000, 1200, 1400]\n",
    "\n",
    "# Try a broad range of initial values - large risks overfitting to small number of training vectors, small risks underfitting.\n",
    "alpha_types = ['per', 'exp']\n",
    "initial_values = [0.1, 0.25, 0.5, 1, 3, 5]\n",
    "\n",
    "# reset weights matrix with size = 15\n",
    "node_matrix = build_node_matrix(15,num_features)\n",
    "\n",
    "\n",
    "for iterations in possible_max_iterations:\n",
    "    params['iterations']=iterations\n",
    "    \n",
    "    # Alpha as an exponential decay function\n",
    "    for alpha_type in alpha_types:\n",
    "        params['alpha_type']=alpha_type \n",
    "        \n",
    "        # Loop through possible initial values\n",
    "        for initial_value in initial_values:\n",
    "            params['initial_val'] = initial_value\n",
    "            \n",
    "            # set half lifes\n",
    "            if alpha_type == 'exp':\n",
    "                decay_hlifes = [0.2, 0.4]\n",
    "                base_filepath = alpha_exp_path\n",
    "            else:\n",
    "                decay_hlifes = [0]   # alpha function ignores decay rate for 'per' function\n",
    "                base_filepath = alpha_per_path\n",
    "\n",
    "            for decay_hlife in decay_hlifes:\n",
    "                params['half_life'] = decay_hlife\n",
    "\n",
    "                # train the matrix with the hyper parameters\n",
    "                trained_matrix = train_matrix(params, node_matrix, training_data)\n",
    "\n",
    "                # Iterate through validation set\n",
    "                for i, test_vector in validation_set:\n",
    "                    # Evaluate the matrix by finding the distance between a test vector and all of the nodes\n",
    "                    distance_matrix = np.array([[distance(test_vector, node) for node in row] for row in trained_matrix])\n",
    "\n",
    "                    # set the filepath\n",
    "                    response_image_path = base_filepath\n",
    "                    \n",
    "                    if alpha_type == 'exp':\n",
    "                        response_image_path += f'/vec{i}_iterations_{iterations}_initval_{initial_value}_decay_{decay_hlife}.png'\n",
    "                    else:\n",
    "                        response_image_path += f'/vec{i}_iterations_{iterations}_initval_{initial_value}.png'\n",
    "                        \n",
    "                    # save response\n",
    "                    record_response(distance_matrix, response_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "##### Summary - extreme values\n",
    "\n",
    "Description | alpha type | number of iterations (train size) | initial value | $h$ (`half life`) | Vector 11 | Vector 2\n",
    "---|---|---|---|---|---|---\n",
    "Exponential alpha function with small train size, small initial value, short half life | exp | 400 | 0.1 | 0.2 | ![response](output/3_2_6/exp/vec11_iterations_400_initval_0.1_decay_0.2.png)|![response](output/3_2_6/exp/vec2_iterations_400_initval_0.1_decay_0.2.png)\n",
    "Exponential alpha function with small train size, large initial value, short half life | exp | 400 | 5 | 0.2 | ![response](output/3_2_6/exp/vec11_iterations_400_initval_5_decay_0.2.png)|![response](output/3_2_6/exp/vec2_iterations_400_initval_5_decay_0.2.png)\n",
    "Exponential alpha function with small train size, small initial value, long half life | exp | 400 | 0.1 | 0.4 | ![response](output/3_2_6/exp/vec11_iterations_400_initval_0.1_decay_0.4.png)|![response](output/3_2_6/exp/vec2_iterations_400_initval_0.1_decay_0.4.png)\n",
    "Exponential alpha function with small train size, large initial value, long half life | exp | 400 | 5 | 0.4 | ![response](output/3_2_6/exp/vec11_iterations_400_initval_5_decay_0.4.png)|![response](output/3_2_6/exp/vec2_iterations_400_initval_5_decay_0.4.png)\n",
    "Exponential alpha function with large train size, small initial value, short half life | exp | 1000 | 0.1 | 0.2 | ![response](output/3_2_6/exp/vec11_iterations_1000_initval_0.1_decay_0.2.png)|![response](output/3_2_6/exp/vec2_iterations_1000_initval_0.1_decay_0.2.png)\n",
    "Exponential alpha function with large train size, large initial value, short half life | exp | 1000 | 5 | 0.2 | ![response](output/3_2_6/exp/vec11_iterations_1000_initval_5_decay_0.2.png)|![response](output/3_2_6/exp/vec2_iterations_1000_initval_5_decay_0.2.png)\n",
    "Exponential alpha function with large train size, small initial value, long half life | exp | 1000 | 0.1 | 0.4 | ![response](output/3_2_6/exp/vec11_iterations_1000_initval_0.1_decay_0.4.png)|![response](output/3_2_6/exp/vec2_iterations_1000_initval_0.1_decay_0.4.png)\n",
    "Exponential alpha function with large train size, large initial value, long half life | exp | 1000 | 5 | 0.4 | ![response](output/3_2_6/exp/vec11_iterations_1000_initval_5_decay_0.4.png)|![response](output/3_2_6/exp/vec2_iterations_1000_initval_5_decay_0.4.png)\n",
    "Fractional alpha function with small train size and small initial value | per | 400 | 0.1 | - | ![response](output/3_2_6/per/vec11_iterations_400_initval_0.1.png)|![response](output/3_2_6/per/vec2_iterations_400_initval_0.1.png)\n",
    "Fractional alpha function with small train size and large initial value | per | 500 | 5 | - | ![response](output/3_2_6/per/vec11_iterations_400_initval_5.png)|![response](output/3_2_6/per/vec2_iterations_400_initval_5.png)\n",
    "Fractional alpha function with large train size and small initial value | per | 1000 | 0.1 | - | ![response](output/3_2_6/per/vec11_iterations_1000_initval_0.1.png)|![response](output/3_2_6/per/vec2_iterations_1000_initval_0.1.png)\n",
    "Fractional alpha function with large train size and large initial value | per | 1000 | 5 | - | ![response](output/3_2_6/per/vec11_iterations_1000_initval_5.png)|![response](output/3_2_6/per/vec2_iterations_1000_initval_5.png)\n",
    "\n",
    "Clearly, an initial value of 5 is generally far too high for the 'per' alpha function and overtrains the matrix.\n",
    "\n",
    "The most distinct clusters arise from intermediary values. Three final candidates (including the exponential alpha function examined above) have been selected as shown below. \n",
    "\n",
    "alpha type | number of iterations (train size) | initial value | $h$ (`half life`) | Vector 2 | Vector 11 | Vector 16 | Vector 24\n",
    "---|---|---|---|---|---|---|---\n",
    "exp | 800 | 0.25 | 0.4 | ![response](output/3_2_6/exp/vec2_iterations_800_initval_0.25_decay_0.4.png)|![response](output/3_2_6/exp/vec11_iterations_800_initval_0.25_decay_0.4.png)|![response](output/3_2_6/exp/vec16_iterations_800_initval_0.25_decay_0.4.png)|![response](output/3_2_6/exp/vec24_iterations_800_initval_0.25_decay_0.4.png)\n",
    "exp | 1200 | 0.5 | 0.2 | ![response](output/3_2_6/exp/vec2_iterations_1200_initval_0.5_decay_0.2.png)|![response](output/3_2_6/exp/vec11_iterations_1200_initval_0.5_decay_0.2.png)|![response](output/3_2_6/exp/vec16_iterations_1200_initval_0.5_decay_0.2.png)|![response](output/3_2_6/exp/vec24_iterations_1200_initval_0.5_decay_0.2.png)\n",
    "per | 1000 | 0.1 | - | ![response](output/3_2_6/per/vec2_iterations_1000_initval_0.1.png)  | ![response](output/3_2_6/per/vec11_iterations_1000_initval_0.1.png)  | ![response](output/3_2_6/per/vec16_iterations_1000_initval_0.1.png)  | ![response](output/3_2_6/per/vec24_iterations_1000_initval_0.1.png)  \n",
    "per | 800 | 0.5 | - | ![response](output/3_2_6/per/vec2_iterations_400_initval_0.5.png)  | ![response](output/3_2_6/per/vec11_iterations_400_initval_0.5.png)  | ![response](output/3_2_6/per/vec16_iterations_400_initval_0.5.png)  | ![response](output/3_2_6/per/vec24_iterations_400_initval_0.5.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these four candidates, the one that displays the greatest contrast between what looks like 4-6 clusters is the fourth one.\n",
    "\n",
    "The selected hyperparameters are therefore:\n",
    "\n",
    "- Size of matrix: 15 x 15\n",
    "- Number of iterations: 1200\n",
    "- Theta function: gaussian\n",
    "- Alpha function: exponential decay with initial value 0.5 and halflife of $0.2 \\times 1200 = 240$ iterations\n",
    "\n",
    "These hyperparameters will be stored in a final SOM algorithm function in `featureextractionsom/somap` and the training data will be applied in the next notebook.\n",
    "\n",
    "## References\n",
    "\n",
    "Tian, J., Azarian, M. H. & Pecht, M. (2014) 'Anomaly Detection Using Self-Organizing Maps-Based K-Nearest Neighbor Algorithm, in _Proceedings of the European Conference of the Prognostics and Health Management Society_, available online at [SemanticScholar.org](https://www.semanticscholar.org/paper/Anomaly-Detection-Using-Self-Organizing-Maps-Based-Tian-Azarian/0cfcffcf796f0f2f2be202222a07584c9474541c) [Accessed 04/03/2020]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (numpysom)",
   "language": "python",
   "name": "pycharm-6cf15ebb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
